# KGE Score Integration Summary

## ðŸŽ¯ ä¿®æ”¹ç›®æ¨™

æ ¹æ“šä½ çš„éœ€æ±‚ï¼Œæˆ‘å€‘å°‡åŽŸæœ¬çš„ KGE embedding æ•´åˆæ–¹å¼æ”¹ç‚º KGE score æ•´åˆæ–¹å¼ï¼š

**åŽŸæœ¬çš„åšæ³•**ï¼šå°‡ KGE çš„ h, r, t embedding åˆ†åˆ¥åŠ åˆ° GTE çš„ h, r, t embedding ä¸Šï¼ˆelement-wise addï¼‰

**æ–°çš„åšæ³•**ï¼š
1. **ä¿æŒåŽŸæœ¬çš„ GTE embedding concatenation**ï¼š`[Zq||Zh||Zr||Zt||Ztau]`
2. **KGE åªæä¾› score**ï¼šå°‡ h, r, t é€šéŽ KGE model è¨ˆç®—å‡ºä¸‰å…ƒçµ„çš„ plausibility score
3. **KGE score ä½œç‚ºé¡å¤–çš„ loss é …**ï¼šä½¿ç”¨ margin ranking lossï¼Œèˆ‡åŽŸæœ¬çš„ BCE loss ç›¸åŠ 

## ðŸ“‹ ä¿®æ”¹çš„æ–‡ä»¶

### 1. `src/model/retriever.py`
- **ä¿®æ”¹å‰**ï¼šKGE embedding èˆ‡ GTE embedding ç›¸åŠ å¾Œ concat
- **ä¿®æ”¹å¾Œ**ï¼šä¿æŒåŽŸæœ¬çš„ GTE embedding concatï¼ŒKGE åªè¨ˆç®— score
- **ä¸»è¦è®Šæ›´**ï¼š
  - ç§»é™¤äº† KGE embedding projection layer
  - ç§»é™¤äº† KGE embedding çš„ concat
  - forward æ–¹æ³•ç¾åœ¨è¿”å›ž `(mlp_logits, kge_score)`

### 2. `train.py`
- **ä¿®æ”¹å‰**ï¼šåªæœ‰ BCE loss
- **ä¿®æ”¹å¾Œ**ï¼šBCE loss + Î» * KGE margin ranking loss
- **ä¸»è¦è®Šæ›´**ï¼š
  - `train_epoch` å‡½æ•¸åŠ å…¥ config åƒæ•¸
  - è¨ˆç®— KGE margin ranking loss
  - ç¸½ loss = BCE loss + Î» * KGE loss
  - è¿”å›žè©³ç´°çš„ loss è³‡è¨Š

### 3. `eval_epoch` å‡½æ•¸
- **ä¿®æ”¹**ï¼šè™•ç†æ¨¡åž‹ç¾åœ¨è¿”å›ž `(mlp_logits, kge_score)` çš„æƒ…æ³

### 4. `inference.py`
- **ä¿®æ”¹**ï¼šè™•ç†æ¨¡åž‹ç¾åœ¨è¿”å›ž `(mlp_logits, kge_score)` çš„æƒ…æ³

### 5. é…ç½®æ–‡ä»¶
- **`configs/retriever/webqsp.yaml`** å’Œ **`configs/retriever/cwq.yaml`**
- **æ–°å¢žåƒæ•¸**ï¼š`kge.loss_weight: 1.0` - æŽ§åˆ¶ KGE loss çš„æ¬Šé‡

### 6. `src/model/kge_models.py`
- **ä¿®æ”¹**ï¼šæ‰€æœ‰ KGE æ¨¡åž‹çš„ `predict` æ–¹æ³•æ–‡æª”ï¼Œèªªæ˜Žæ”¯æŒæ‰¹æ¬¡è¼¸å…¥

## ðŸ—ï¸ æ–°çš„æž¶æ§‹

### æ¨¡åž‹ Forward æµç¨‹
```
è¼¸å…¥: [Zq||Zh||Zr||Zt||Ztau] (GTE + DDE + PE)
    â†“
MLP â†’ mlp_logits
    â†“
KGE Model â†’ kge_score
    â†“
è¿”å›ž: (mlp_logits, kge_score)
```

### è¨“ç·´ Loss è¨ˆç®—
```
BCE Loss = binary_cross_entropy_with_logits(mlp_logits, target_triple_probs)

KGE Margin Ranking Loss = max(0, pos_kge_scores - neg_kge_scores + margin)

Total Loss = BCE Loss + Î» * KGE Margin Ranking Loss
```

## ðŸš€ ä½¿ç”¨æ–¹æ³•

### 1. é…ç½® KGE
åœ¨é…ç½®æ–‡ä»¶ä¸­è¨­ç½®ï¼š
```yaml
kge:
  enabled: true
  model_type: 'transe'  # æˆ–å…¶ä»– KGE æ¨¡åž‹
  embedding_dim: 256
  margin: 1.0
  loss_weight: 1.0  # æ–°å¢žï¼šKGE loss æ¬Šé‡
```

### 2. è¨“ç·´
```bash
python train.py --dataset webqsp
```

### 3. æŽ¨è«–
```bash
python inference.py --path path/to/checkpoint.pth
```

## âœ… é©—è­‰

å‰µå»ºäº†æ¸¬è©¦è…³æœ¬ `test_kge_score_integration.py` ä¾†é©—è­‰ï¼š
- KGE æ¨¡åž‹èƒ½æ­£ç¢ºè¨ˆç®— score
- Retriever æ¨¡åž‹èƒ½æ­£ç¢ºæ•´åˆ KGE score
- Margin ranking loss èƒ½æ­£ç¢ºè¨ˆç®—
- æ‰€æœ‰çµ„ä»¶èƒ½æ­£å¸¸å”ä½œ

æ¸¬è©¦çµæžœï¼šâœ… æ‰€æœ‰æ¸¬è©¦é€šéŽ

## ðŸ”§ æŠ€è¡“ç´°ç¯€

### KGE Score è¨ˆç®—
- ä½¿ç”¨ KGE æ¨¡åž‹çš„ `predict` æ–¹æ³•
- æ”¯æŒæ‰¹æ¬¡è¼¸å…¥
- è¿”å›žä¸‰å…ƒçµ„çš„ plausibility score

### Margin Ranking Loss
- æ­£æ¨£æœ¬ï¼š`target_triple_probs > 0.5`
- è² æ¨£æœ¬ï¼š`target_triple_probs <= 0.5`
- è¨ˆç®—ï¼š`max(0, pos_scores - neg_scores + margin)`

### Loss æ¬Šé‡
- å¯é€šéŽ `kge.loss_weight` èª¿æ•´ KGE loss çš„å½±éŸ¿
- é è¨­å€¼ï¼š1.0
- å»ºè­°ç¯„åœï¼š0.1 - 2.0

## ðŸ“Š é æœŸæ•ˆæžœ

1. **æ›´ç´”ç²¹çš„ KGE æ•´åˆ**ï¼šKGE ä½œç‚ºç¨ç«‹çš„ç›£ç£ä¿¡è™Ÿï¼Œä¸å¹²æ“¾ GTE embedding
2. **æ›´å¥½çš„å¯è§£é‡‹æ€§**ï¼šå¯ä»¥åˆ†åˆ¥è§€å¯Ÿ MLP å’Œ KGE çš„è¡¨ç¾
3. **æ›´éˆæ´»çš„èª¿å„ª**ï¼šå¯ä»¥ç¨ç«‹èª¿æ•´ KGE loss çš„æ¬Šé‡
4. **æ›´ç©©å®šçš„è¨“ç·´**ï¼šé¿å… embedding ç¶­åº¦ä¸åŒ¹é…çš„å•é¡Œ

## ðŸŽ‰ ç¸½çµ

æˆåŠŸå¯¦ç¾äº†ä½ è¦æ±‚çš„ KGE score æ•´åˆæ–¹å¼ï¼š
- âœ… ä¿æŒåŽŸæœ¬çš„ GTE embedding concatenation
- âœ… KGE åªæä¾› scoreï¼Œä¸æ”¹è®Š embedding çµæ§‹
- âœ… ä½¿ç”¨ margin ranking loss ä½œç‚ºé¡å¤–çš„ç›£ç£ä¿¡è™Ÿ
- âœ… æ”¯æŒå¯é…ç½®çš„ loss æ¬Šé‡
- âœ… æ‰€æœ‰çµ„ä»¶ç¶“éŽæ¸¬è©¦é©—è­‰ 